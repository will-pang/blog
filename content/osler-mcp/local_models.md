---
title: Local Models
date: 2026-01-04
tags:
  - mcp
  - local
---

As proprietary models (e.g., GPT-5.2, Claude Opus 4.5) continue to improve and re-define what is [state-of-the-art](https://gorilla.cs.berkeley.edu/leaderboard.html), it's been equally exciting to see [local models](https://www.linkedin.com/posts/julienchaumond_2026-will-be-the-year-of-local-agents-activity-7411141868303896576-F-VI?utm_source=share&utm_medium=member_desktop&rcm=ACoAABoaxBEBSWALU6nGy5nzir-14PSH_-PQlvQ) improve drastically in capabilities and crush ["older"](https://github.com/idavidrein/gpqa) benchmarks. Admittedly, I haven't played around with open-sourced models since ðŸ¦™ Llama was a community favorite (but not [anymore](https://magazine.sebastianraschka.com/p/state-of-llms-2025)), so I was excited to once again hear my laptop fans kick into full gear and (mentally) feel better about the _costly_ capital expenditure of my Macbook Pro.

### Setting up the local model

I wanted to be able to set something up quickly for experimentation, so my main requirements were (1) something that I could setup with relatively little pain (2) something that would be compatible with Apple Silicon chips.

### Evals, again!

### So why open sourced?

I was having a conversation with a friend earlier this week who wanted to pick my brain on whether to use an open model, or stick with a properity model and leverage their fine-tuning [services](https://platform.openai.com/docs/guides/supervised-fine-tuning?formatting=jsonl).
